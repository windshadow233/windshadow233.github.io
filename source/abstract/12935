本文介绍了在消费级显卡上部署QwQ-32B模型的方法。通过4bit量化，32B模型仅需16G显存，可在24G显存的NVIDIA GeForce RTX 3090上部署。部署步骤包括下载模型、安装llama.cpp框架、创建jinja模板和启动命令文件。最终通过运行脚本完成部署，并在Cherry Studio中测试了模型的工具调用功能。