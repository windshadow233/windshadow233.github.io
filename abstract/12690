本文介绍了大语言模型训练中的监督微调（SFT）阶段。SFT通过使用特定任务的人类标注数据对预训练模型进行微调，让模型学会按人类意图作答。文中讲解了数据处理方法、LoRA轻量级微调技术及其实现，以及SFT的训练目标。SFT使模型从通用语言能力升级到任务导向能力，为后续人类反馈优化（RLHF）奠定基础。